##Downloading SRA - https://www.ncbi.nlm.nih.gov/sra/docs/sradownload/
fasterq-dump --split-files SRR11180057

Running Trimmomatic on SRA sequences/raw reads downloaded from NCBI SRA toolkit (SRR*_1.fastq.gz, SRR*_2.fastq.gz) - pipeline : UCE phylogenomics
Note: Running Trimmomatic instead for illumiprocessor (Phyluce), and then joining back to Assembly step

Steps: Open Ubuntu, enter path to raw reads (raw-fastq), conda activate phyluce-1.7.1
#run the below code
#renaming SRA sequences with species name and voucher ID
awk -F',' '{ gsub(/\r/, "", $1); gsub(/\r/, "", $2); gsub(/^ *| *$/, "", $1); gsub(/^ *| *$/, "", $2); system("mv \"" $1 "\" \"" $2 "\"") }' name-test.csv

for infile in *_1.fastq.gz; do base=$(basename ${infile} _1.fastq.gz); trimmomatic PE -threads 4 ${infile} ${base}_2.fastq.gz ${base}_1.trim.fastq.gz ${base}_1un.trim.fastq.gz ${base}_2.trim.fastq.gz ${base}_2un.trim.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:True LEADING:3 TRAILING:3 MINLEN:36; done

running on 17-01-2023 and 30-01-2023, editing on 25-7-24

for infile in *_1.fastq.gz; do base=$(basename ${infile} _1.fastq.gz); trimmomatic PE -trimlog log -threads 10 ${infile} ${base}_2.fastq.gz ${base}_1.trim.fastq.gz ${base}_1un.trim.fastq.gz ${base}_2.trim.fastq.gz ${base}_2un.trim.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:True SLIDINGWINDOW:4:20 MINLEN:25; done

trimmomatic PE -threads 4 T_fumigatus_GNM-Av.ex_7455_1.fastq.gz T_fumigatus_GNM-Av.ex_7455_2.fastq.gz T_fumigatus_GNM-Av.ex_7455_1.trim.fastq.gz T_fumigatus_GNM-Av.ex_7455_1un.trim.fastq.gz T_fumigatus_GNM-Av.ex_7455_2.trim.fastq.gz T_fumigatus_GNM-Av.ex_7455_2un.trim.fastq.gz ILLUMINACLIP:TruSeq3-PE.fa:2:30:10:2:True SLIDINGWINDOW:4:20 MINLEN:25

#since trimmed files are created in the same folder as raw reads, we move them to new folder (clean-fastq)

mv raw-fastq-renamed/*.trim* trim-fastq-slidingwindow-minlen
mv raw-fastq-ibb/raw-fastq-wgs/*.trim* trim-fastq-ibb-wgs-slidingwindow-minlen

#renaming unpaired reads to singleton
for prefix in $(ls *_1un.trim.fastq.gz | sed 's/_1un.trim.fastq.gz//'); do cat "${prefix}_1un.trim.fastq.gz" "${prefix}_2un.trim.fastq.gz" > "${prefix}_READ-singleton.fastq.gz" gzip "${prefix}_READ-singleton.fastq.gz"; done
rm *un.trim.fastq.gz

#renaming paired reads as READ1 and READ2

for infile in *_1.trim.fastq.gz; do base=$(basename ${infile} _1.trim.fastq.gz); mv ${infile} ${base}_READ1.fastq.gz; done
for infile in *_2.trim.fastq.gz; do base=$(basename ${infile} _2.trim.fastq.gz); mv ${infile} ${base}_READ2.fastq.gz; done

#renaming SRR* sequence name to Genus_species_voucher format
#create csv file - with two columns <oldname> <newname>(SRR*_READ1.fastq.gz > C_virdis_BTC850_READ1.fastq.gz)
#windows created csv maybe  hard to read when running on ubuntu, one way out maybe to rename raw-fastq files before trimming

awk -F',' '{ gsub(/\r/, "", $1); gsub(/\r/, "", $2); gsub(/^ *| *$/, "", $1); gsub(/^ *| *$/, "", $2); system("mv \"" $1 "\" \"" $2 "\"") }' name-test.csv

#put in species specific folders
# Get unique prefixes from the filenames
prefixes=($(ls *_READ1.fastq.gz | sed 's/_READ1.fastq.gz//'))

# Loop over each prefix
for prefix in "${prefixes[@]}"; do
  dir_name="${prefix}"

  # Create directory if it doesn't exist
  mkdir -p "${dir_name}"

  # Move files into the directory
  mv "${prefix}"_READ1.fastq.gz "${prefix}"_READ2.fastq.gz "${prefix}"_READ-singleton.fastq.gz "${dir_name}/"
done

# Loop over each prefix
for prefix in "${prefixes[@]}"; do
  dir_name="${prefix}"

  # Create directory if it doesn't exist
  mkdir -p "${dir_name}"

  # Move files into the directory
  mv "${prefix}".2bit "${prefix}".chrom.sizes "${dir_name}/"
done
